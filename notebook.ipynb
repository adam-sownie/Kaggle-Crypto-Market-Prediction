{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6cfc6-a80b-48ab-a4e9-d8c4ef1808b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "%pip install fastparquet\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import fastparquet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1167f8b-b718-4323-858d-68dd57cf28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_parquet('train.parquet')\n",
    "    print(\"Successfully loaded parquet file with existing engine\")\n",
    "except ImportError as e:\n",
    "    print(\"ParquetEngine not found. Installing pyarrow...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow\"])\n",
    "    print(\"pyarrow installed. Attempting to load parquet file again...\")\n",
    "    df = pd.read_parquet('train.parquet')\n",
    "except FileNotFoundError:\n",
    "    print(\"train.parquet not found. Please ensure the file is in the current directory.\")\n",
    "    print(\"Alternative: If you have a CSV file, change the filename below:\")\n",
    "    # df = pd.read_csv('train.csv')  # Uncomment and modify if using CSV\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Error loading parquet file: {e}\")\n",
    "    print(\"Trying with fastparquet engine...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"fastparquet\"])\n",
    "        df = pd.read_parquet('train.parquet', engine='fastparquet')\n",
    "    except:\n",
    "        print(\"Failed to load with fastparquet. Please install manually:\")\n",
    "        print(\"Run: pip install pyarrow\")\n",
    "        print(\"Or: pip install fastparquet\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068902c-dfe3-4fdc-971f-bd01b1ffe1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946ab5a-831b-46a4-9f06-8169540a3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # Drop specified columns (mix of unique and duplicate columns)\n",
    "    cols_to_drop = ['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716', 'X717', 'X864', 'X867', 'X869', 'X870', 'X871', 'X872'] + ['X104', 'X146', 'X110', 'X152', 'X116', 'X158', 'X122', 'X164', 'X128', 'X170', 'X134', 'X176', 'X140', 'X182', 'X351', 'X393', 'X357', 'X399', 'X363', 'X405', 'X369', 'X411', 'X375', 'X417', 'X381', 'X423', 'X387', 'X429']\n",
    "    \n",
    "    # Only drop columns that actually exist in the dataframe\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df.drop(columns=cols_to_drop_existing, inplace=True)\n",
    "\n",
    "preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c2ff9-08c1-49f9-8eba-fdce6f62a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA EXPLORATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b5fc8-2969-4bb6-83e6-c613aaca2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_count = df.isnull().sum().sum()\n",
    "print(f\"Missing values found: {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(\"Handling missing values...\")\n",
    "    \n",
    "    # Check for columns that are entirely NaN\n",
    "    all_nan_cols = df.columns[df.isnull().all()].tolist()\n",
    "    if all_nan_cols:\n",
    "        print(f\"Found {len(all_nan_cols)} columns with all NaN values - dropping them\")\n",
    "        df = df.drop(columns=all_nan_cols)\n",
    "    \n",
    "    # Handle remaining missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if df[col].dtype in ['object', 'category']:\n",
    "                mode_val = df[col].mode()\n",
    "                df[col] = df[col].fillna(mode_val[0] if len(mode_val) > 0 else 'unknown')\n",
    "            else:\n",
    "                # Check if column has any non-NaN values before calculating median\n",
    "                non_nan_count = df[col].count()\n",
    "                if non_nan_count > 0:\n",
    "                    median_val = df[col].median()\n",
    "                    df[col] = df[col].fillna(median_val)\n",
    "                else:\n",
    "                    # If somehow still all NaN, fill with 0\n",
    "                    df[col] = df[col].fillna(0)\n",
    "    print(\"Missing values filled\")\n",
    "else:\n",
    "    print(\"No missing values found\")\n",
    "\n",
    "# Check for infinite values\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "inf_count = np.isinf(df[numeric_cols]).sum().sum()\n",
    "print(f\"Infinite values found: {inf_count}\")\n",
    "\n",
    "if inf_count > 0:\n",
    "    print(\"Handling infinite values...\")\n",
    "    # Replace inf with NaN, then fill with median\n",
    "    df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            # Check if column has any non-NaN values before calculating median\n",
    "            non_nan_count = df[col].count()\n",
    "            if non_nan_count > 0:\n",
    "                median_val = df[col].median()\n",
    "                df[col] = df[col].fillna(median_val)\n",
    "            else:\n",
    "                # If all NaN, fill with 0\n",
    "                df[col] = df[col].fillna(0)\n",
    "    print(\"Infinite values replaced with median values\")\n",
    "else:\n",
    "    print(\"No infinite values found\")\n",
    "\n",
    "# Check for very large values that might cause issues\n",
    "large_value_threshold = 1e10\n",
    "large_values = (np.abs(df[numeric_cols]) > large_value_threshold).sum().sum()\n",
    "print(f\"Very large values (>{large_value_threshold}): {large_values}\")\n",
    "\n",
    "if large_values > 0:\n",
    "    print(\"Clipping very large values...\")\n",
    "    for col in numeric_cols:\n",
    "        df[col] = np.clip(df[col], -large_value_threshold, large_value_threshold)\n",
    "    print(\"Large values clipped to reasonable range\")\n",
    "else:\n",
    "    print(\"No extremely large values found\")\n",
    "\n",
    "print(\"Data preprocessing complete - ready for XGBoost training\")\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6100f05-7fc1-475f-99c3-ac02b0b6744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "target_col = 'label'  # Target column name\n",
    "if target_col not in df.columns:\n",
    "    print(f\"Target column '{target_col}' not found. Available columns: {list(df.columns)}\")\n",
    "    raise ValueError(f\"Column '{target_col}' not found in dataset\")\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463b8e1-fe30-46a9-b8d3-92f4f778f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target if it's categorical\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    target_encoder = LabelEncoder()\n",
    "    y = target_encoder.fit_transform(y)\n",
    "    print(f\"Target classes: {target_encoder.classes_}\")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{pd.Series(y).value_counts()}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfc5a6-db80-419d-80f1-7db551b9c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearson_eval(y_true, y_pred):\n",
    "    \"\"\"Custom evaluation metric for XGBoost using Pearson correlation\"\"\"\n",
    "    try:\n",
    "        # Ensure arrays are numpy arrays and not empty\n",
    "        y_true = np.asarray(y_true).flatten()\n",
    "        y_pred = np.asarray(y_pred).flatten()\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if len(y_true) == 0 or len(y_pred) == 0:\n",
    "            return 'pearson', -1.0\n",
    "            \n",
    "        # Check for constant arrays (zero variance)\n",
    "        if np.var(y_true) == 0 or np.var(y_pred) == 0:\n",
    "            return 'pearson', -1.0\n",
    "            \n",
    "        # Calculate correlation\n",
    "        correlation, _ = pearsonr(y_true, y_pred)\n",
    "        \n",
    "        # Handle NaN case\n",
    "        if np.isnan(correlation):\n",
    "            correlation = -1.0\n",
    "            \n",
    "        # Return negative correlation because XGBoost minimizes metrics\n",
    "        return 'pearson', -float(correlation)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in pearson_eval: {e}\")\n",
    "        return 'pearson', -1.0\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Train XGBoost model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBOOST TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=pearson_eval  # Use custom Pearson correlation metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05faee5-768a-4e91-bc9c-ffe27b7bdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "xgb_model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)], \n",
    "    verbose=10  # Show progress every 10 rounds to see the pearson metric\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "    \n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "pearson_corr, p_value = pearsonr(y_test, y_pred)\n",
    "    \n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
    "print(f\"Pearson p-value: {p_value:.6f}\")\n",
    "\n",
    "# The training output should now show the pearson metric (as negative values)\n",
    "# Remember: XGBoost shows -correlation, so -0.8 means correlation of 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec0612-368d-43b5-a3e3-bfb82aa9a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5e136-d733-4657-966d-98bcb2dcc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(xgb_model, 'xgboost_model.pkl')\n",
    "print(\"Model saved as 'xgboost_model.pkl'\")\n",
    "print(\"(No label encoders needed - all numeric data)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8f18e-6818-47d9-947c-9779ca622b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test.parquet')\n",
    "preprocess_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc2dc1-0eea-4527-97c4-9a0b3b139669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for prediction\n",
    "# Remove the 'label' column since it's just placeholder zeros\n",
    "if 'label' in test_df.columns:\n",
    "    X_test_submission = test_df.drop('label', axis=1)\n",
    "else:\n",
    "    X_test_submission = test_df.copy()\n",
    "\n",
    "# Make sure we have an ID column for the submission\n",
    "# If your test_df has an 'ID' column, use that\n",
    "# If not, you might need to create one or check what the ID column is called\n",
    "if 'ID' in test_df.columns:\n",
    "    test_ids = test_df['ID']\n",
    "    # Remove ID from features if it exists\n",
    "    if 'ID' in X_test_submission.columns:\n",
    "        X_test_submission = X_test_submission.drop('ID', axis=1)\n",
    "else:\n",
    "    # If no ID column, create one (check your competition requirements)\n",
    "    test_ids = range(1, len(test_df) + 1)\n",
    "    print(\"Warning: No ID column found, using row indices\")\n",
    "\n",
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions = xgb_model.predict(X_test_submission)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file saved! Shape: {submission_df.shape}\")\n",
    "print(\"First few rows:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Optional: Quick sanity checks\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"Min: {test_predictions.min():.4f}\")\n",
    "print(f\"Max: {test_predictions.max():.4f}\")\n",
    "print(f\"Mean: {test_predictions.mean():.4f}\")\n",
    "print(f\"Std: {test_predictions.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3907eb3-6792-4622-ab3c-14acd9988957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/working')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, use the built-in submission mechanism\n",
    "    print(\"Running on Kaggle - please use the 'Submit' button in the UI to submit your results\")\n",
    "else:\n",
    "    # If running locally, use the Kaggle API to submit\n",
    "    print(\"Submitting via Kaggle API...\")\n",
    "    \n",
    "    # Ensure Kaggle API is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "    \n",
    "    # Submit the file\n",
    "    # Note: Make sure you have Kaggle API credentials set up (~/.kaggle/kaggle.json)\n",
    "    competition_name = \"drw-crypto-market-prediction\"\n",
    "    submission_message = \"initial xgboost\"\n",
    "    \n",
    "    # Command to submit \n",
    "    submission_command = f\"kaggle competitions submit -c {competition_name} -f submission.csv -m \\\"{submission_message}\\\"\"\n",
    "    \n",
    "    print(f\"Running command: {submission_command}\")\n",
    "    !{submission_command}\n",
    "    \n",
    "    # Check your submissions (optional)\n",
    "    print(\"\\nYour recent submissions:\")\n",
    "    !kaggle competitions submissions -c {competition_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3acc6-928c-4f67-bc6b-cc0556693839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAI (GPU)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
